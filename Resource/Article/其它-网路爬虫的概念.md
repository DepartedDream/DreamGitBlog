# 网络爬虫简介

* 网络爬虫即Web Spider，又叫做网络蜘蛛
* 网络爬虫是一种按照一定的规则，自动地抓取网路信息的程序
* HTML代码META标签可以告诉网络爬虫本网页是否需要被抓取，还可 以告诉网络爬虫本网页中的链接是否需要被继续跟踪。
* 网络爬虫抓取的时候，评价重要性主要的依据是某个网页的链接深度。

# 网络爬虫的两种策略

## 广度优先抓取

* 广度优先是指网络爬虫会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。
* 广度优先这是最常用的方式，
* 广度优先可以让网络爬虫并行处理，提高其抓取速度。

## 深度优先抓取

* 深度优先抓取是指网络爬虫会从起始页开始，一个链接一个链接跟踪下去，处理完这条线路之后再转入下一个起始页，继续跟踪链接。
* 深度优先抓取在设计的时候比较容易。
* 有些网络爬虫对一些不太重要的网站，设置了访问的层数

# 网站与网络爬虫的交流

* 网站希望搜索引擎爬虫能更全面的抓取自己网站,可以加大浏览量
* 网站可以把所有的链接放在SiteMap文件里，那么网络蜘蛛可以很方便的把整个网站抓取下来，避免遗漏某些网页，也会减小对网站服务器的负担。
* 如果不对网络爬虫的访问进行控制，则可能会引起网站服务器负担过重
* User-agent，用于标识网络爬虫的身份

# Robots.txt

* Robots.txt是一个定义网络爬虫可访问目录的协议，网络爬虫的设计者可以不遵循这个协议，
* Robots.txt一般放在网站服务器的根目录下，

# 网络爬虫的更新周期

* 由于网站的内容经常在变化，因此网络爬虫也需不断的更新其抓取网页的内容，
* 这就需要网络爬虫按照一定的周期去扫描网站，查看哪些页面是需要更新的页面，哪些页面是新增页面，哪些页面是已经过期的死链接。
* 搜索引擎的更新周期对搜索引擎搜索的查全率有很大影响。如果更新周期太长，则总会有一部分新生成的网页搜索不到；周期过短，技术实现会有一定难度，而且会 对带宽、服务器的资源都有浪费。
* 搜索引擎的网络爬虫并不是所有的网站都采用同一个周期进行更新，对于一些重要的更新量大的网站，更新的周期短，如有些新闻 网站，几个小时就更新一次；相反对于一些不重要的网站，更新的周期就长，可能一两个月才更新一次。
* 一般来说，网络爬虫在更新网站内容的时候，不用把网站网页重新抓取一遍，对于大部分的网页，只需要判断网页的属性（主要是日期），把得到的属性和上次抓取的属性相比较，如果一样则不用更新。

# 参考

[C#实现网络爬虫](https://www.cnblogs.com/cgli/archive/2011/11/07/2240440.html)